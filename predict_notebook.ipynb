{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed fixed at 42\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Bước 1: Cố định seed (chỉnh lại số seed nếu đội muốn)\n",
        "\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(42)\n",
        "print(\"Seed fixed at 42\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA_DIR = ../data/public_test/public_test/samples\n",
            "MODEL_PATH = saved_models/yolov8l_1e.pt\n",
            "Found 6 cases.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
            "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_22768\\2030313176.py:12: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  \"public_test\\samples\",\n"
          ]
        }
      ],
      "source": [
        "# Bước 2: Nạp mô hình và các tài nguyên cần thiết\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "from ultralytics import YOLO\n",
        "\n",
        "from predict import AeroEyesPredictor\n",
        "\n",
        "# Đường dẫn mặc định giống predict.py\n",
        "DATA_DIR = os.getenv(\n",
        "    \"DATA_DIR\",\n",
        "    \"public_test\\samples\",\n",
        ")\n",
        "MODEL_PATH = \"saved_models/yolov8l_1e.pt\"\n",
        "\n",
        "print(f\"DATA_DIR = {DATA_DIR}\")\n",
        "print(f\"MODEL_PATH = {MODEL_PATH}\")\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    raise FileNotFoundError(f\"Model not found at {MODEL_PATH}\")\n",
        "\n",
        "# Khởi tạo biến dùng lại ở cell sau\n",
        "predictor = None\n",
        "\n",
        "# Lấy danh sách các case (sub-folder) trong DATA_DIR\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    raise FileNotFoundError(f\"Data directory not found at {DATA_DIR}\")\n",
        "\n",
        "subfolders = sorted([f.path for f in os.scandir(DATA_DIR) if f.is_dir()])\n",
        "print(f\"Found {len(subfolders)} cases.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usable test cases: 6\n",
            "{'case_name': 'BlackBox_0', 'video_path': '../data/public_test/public_test/samples\\\\BlackBox_0\\\\drone_video.mp4', 'ref_images_path': '../data/public_test/public_test/samples\\\\BlackBox_0\\\\object_images'}\n",
            "{'case_name': 'BlackBox_1', 'video_path': '../data/public_test/public_test/samples\\\\BlackBox_1\\\\drone_video.mp4', 'ref_images_path': '../data/public_test/public_test/samples\\\\BlackBox_1\\\\object_images'}\n",
            "{'case_name': 'CardboardBox_0', 'video_path': '../data/public_test/public_test/samples\\\\CardboardBox_0\\\\drone_video.mp4', 'ref_images_path': '../data/public_test/public_test/samples\\\\CardboardBox_0\\\\object_images'}\n",
            "{'case_name': 'CardboardBox_1', 'video_path': '../data/public_test/public_test/samples\\\\CardboardBox_1\\\\drone_video.mp4', 'ref_images_path': '../data/public_test/public_test/samples\\\\CardboardBox_1\\\\object_images'}\n",
            "{'case_name': 'LifeJacket_0', 'video_path': '../data/public_test/public_test/samples\\\\LifeJacket_0\\\\drone_video.mp4', 'ref_images_path': '../data/public_test/public_test/samples\\\\LifeJacket_0\\\\object_images'}\n"
          ]
        }
      ],
      "source": [
        "# Bước 3: Đọc nội dung từng test case (danh sách video + thư mục ref)\n",
        "\n",
        "cases = []\n",
        "for folder_path in subfolders:\n",
        "    case_name = os.path.basename(folder_path)\n",
        "    video_path = os.path.join(folder_path, \"drone_video.mp4\")\n",
        "    ref_images_path = os.path.join(folder_path, \"object_images\")\n",
        "\n",
        "    if not os.path.exists(video_path):\n",
        "        # Bỏ qua case không đủ dữ liệu\n",
        "        continue\n",
        "\n",
        "    cases.append(\n",
        "        {\n",
        "            \"case_name\": case_name,\n",
        "            \"video_path\": video_path,\n",
        "            \"ref_images_path\": ref_images_path,\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(f\"Usable test cases: {len(cases)}\")\n",
        "for c in cases[:5]:\n",
        "    print(c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Timing cases:   0%|          | 0/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 3 reference colors.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Timing cases:   0%|          | 0/6 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     68\u001b[39m frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m box = \u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_streaming\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_rgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m box \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_detections:\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\AI Research\\ZALO-AI-2025\\code\\predict.py:124\u001b[39m, in \u001b[36mAeroEyesPredictor.predict_streaming\u001b[39m\u001b[34m(self, frame_rgb_np, frame_idx)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_streaming\u001b[39m(\u001b[38;5;28mself\u001b[39m, frame_rgb_np, frame_idx):\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m         results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m            \u001b[49m\u001b[43mframe_rgb_np\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconf_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[43miou\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# NMS iou threshold\u001b[39;49;00m\n\u001b[32m    129\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    131\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\model.py:540\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.predictor, \u001b[33m\"\u001b[39m\u001b[33mset_prompts\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[32m    539\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.set_prompts(prompts)\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor.predict_cli(source=source) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:225\u001b[39m, in \u001b[36mBasePredictor.__call__\u001b[39m\u001b[34m(self, source, model, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_inference(source, model, *args, **kwargs)\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\_contextlib.py:38\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     41\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     42\u001b[39m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:327\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m     im = \u001b[38;5;28mself\u001b[39m.preprocess(im0s)\n\u001b[32m    326\u001b[39m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprofilers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\utils\\ops.py:59\u001b[39m, in \u001b[36mProfile.__exit__\u001b[39m\u001b[34m(self, type, value, traceback)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):\n\u001b[32m     58\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Stop timing.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28mself\u001b[39m.dt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m - \u001b[38;5;28mself\u001b[39m.start  \u001b[38;5;66;03m# delta-time\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.t += \u001b[38;5;28mself\u001b[39m.dt\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\\utils\\ops.py:69\u001b[39m, in \u001b[36mProfile.time\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get current time with CUDA synchronization if applicable.\"\"\"\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cuda:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m time.perf_counter()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\cuda\\__init__.py:1085\u001b[39m, in \u001b[36msynchronize\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m   1083\u001b[39m _lazy_init()\n\u001b[32m   1084\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.cuda.device(device):\n\u001b[32m-> \u001b[39m\u001b[32m1085\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Bước 4: Thực hiện dự đoán, đo thời gian và ghi kết quả\n",
        "\n",
        "import json\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Hàm ghi file kết quả giống predict.py\n",
        "\n",
        "def convert(o):\n",
        "    if isinstance(o, np.integer):\n",
        "        return int(o)\n",
        "    if isinstance(o, np.floating):\n",
        "        return float(o)\n",
        "    if isinstance(o, np.ndarray):\n",
        "        return o.tolist()\n",
        "    return o\n",
        "\n",
        "\n",
        "def write_predict_file(results, output_path=\"output.json\"):\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(results, f, indent=4, default=convert)\n",
        "\n",
        "\n",
        "def write_time_file(all_predicted_time, time_path=\"time_submission.csv\"):\n",
        "    # time_submission.csv: 2 cột: case_name, time_ms\n",
        "    import csv\n",
        "\n",
        "    with open(time_path, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"case_name\", \"time_ms\"])  # header\n",
        "        for case_name, t_ms in all_predicted_time:\n",
        "            writer.writerow([case_name, t_ms])\n",
        "\n",
        "\n",
        "all_results = []\n",
        "all_predicted_time = []\n",
        "\n",
        "for case in tqdm(cases, desc=\"Timing cases\"):\n",
        "    case_name = case[\"case_name\"]\n",
        "    video_path = case[\"video_path\"]\n",
        "    ref_images_path = case[\"ref_images_path\"]\n",
        "\n",
        "    # Nạp mô hình & tài nguyên cho từng case (theo đúng yêu cầu: từ load -> inference)\n",
        "    t1 = time()\n",
        "    predictor = AeroEyesPredictor(\n",
        "        MODEL_PATH,\n",
        "        ref_images_path,\n",
        "        conf_threshold=0.001,\n",
        "        color_tol=20.0,\n",
        "    )\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Skip {case_name}: cannot open video\")\n",
        "        continue\n",
        "\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    frame_idx = 0\n",
        "    case_result = {\"video_id\": case_name, \"detections\": []}\n",
        "    has_detections = False\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        box = predictor.predict_streaming(frame_rgb, frame_idx)\n",
        "\n",
        "        if box is not None:\n",
        "            if not has_detections:\n",
        "                case_result[\"detections\"].append({\"bboxes\": []})\n",
        "                has_detections = True\n",
        "\n",
        "            case_result[\"detections\"][0][\"bboxes\"].append(\n",
        "                {\n",
        "                    \"frame\": int(frame_idx),\n",
        "                    \"x1\": int(box[0]),\n",
        "                    \"y1\": int(box[1]),\n",
        "                    \"x2\": int(box[2]),\n",
        "                    \"y2\": int(box[3]),\n",
        "                }\n",
        "            )\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    all_results.append(case_result)\n",
        "\n",
        "    t2 = time()\n",
        "    predicted_time_ms = int((t2 - t1) * 1000)\n",
        "    all_predicted_time.append((case_name, predicted_time_ms))\n",
        "    print(f\"Case {case_name} time: {predicted_time_ms} ms\")\n",
        "\n",
        "# Ghi file kết quả và file thời gian\n",
        "write_predict_file(all_results, output_path=\"output.json\")\n",
        "write_time_file(all_predicted_time, time_path=\"time_submission.csv\")\n",
        "\n",
        "print(\"Done timing. Results saved to output.json and time_submission.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
